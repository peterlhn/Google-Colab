{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Image Search",
      "provenance": [],
      "authorship_tag": "ABX9TyNJEgubVxTaGQumH7EzuQWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterlhn/Google-Colab/blob/master/Google_Image_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BeautifulSoup - Work!**\n",
        "[Scrape and download Google Images with Python](https://medium.com/geekculture/scrape-google-images-with-python-f9a20cda1355)"
      ],
      "metadata": {
        "id": "Xm9NXxNIPU04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Return ONE FULL image link - Based on two method below**"
      ],
      "metadata": {
        "id": "CUqxjVTwbIPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, lxml, re, datetime\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\":\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"q\": \"the matrix\",\n",
        "    \"tbm\": \"isch\",\n",
        "    \"ijn\": \"0\",\n",
        "}\n",
        "\n",
        "html = requests.get(\"https://www.google.com/search\", params=params, headers=headers)\n",
        "soup = BeautifulSoup(html.text, 'lxml')"
      ],
      "metadata": {
        "id": "Ob2S2QPPbRap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_google_image_one_fullsize():\n",
        "    # # this steps could be refactored to a more compact\n",
        "    all_script_tags = soup.select('script')\n",
        "    matched_images_data = ''.join(re.findall(r\"AF_initDataCallback\\(([^<]+)\\);\", str(all_script_tags)))\n",
        "\n",
        "    # if you try to json.loads() without json.dumps() it will throw an error:\n",
        "    # \"Expecting property name enclosed in double quotes\"\n",
        "    matched_images_data_fix = json.dumps(matched_images_data)\n",
        "    matched_images_data_json = json.loads(matched_images_data_fix)\n",
        "\n",
        "    matched_google_image_data = re.findall(r'\\[\\\"GRID_STATE0\\\",null,\\[\\[1,\\[0,\\\".*?\\\",(.*),\\\"All\\\",', matched_images_data_json)\n",
        "\n",
        "    matched_google_images_thumbnails = ', '.join(\n",
        "        re.findall(r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]',\n",
        "                   str(matched_google_image_data))).split(', ')\n",
        "\n",
        "\n",
        "    # # removing previously matched thumbnails for easier full resolution image matches.\n",
        "    removed_matched_google_images_thumbnails = re.sub(\n",
        "        r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]', '', str(matched_google_image_data))\n",
        "\n",
        "    matched_google_full_resolution_images = re.findall(r\"(?:'|,),\\[\\\"(https:|http.*?)\\\",\\d+,\\d+\\]\",\n",
        "                                                       removed_matched_google_images_thumbnails)\n",
        "\n",
        "\n",
        "    # ---------- ONE Image in Full Size ----------- #\n",
        "    print('\\nFull Resolution Images:')  # in order\n",
        "    # Pick the first one from the list from BS\n",
        "    ONE_matched_google_full_resolution_images =  matched_google_full_resolution_images[0]\n",
        "\n",
        "    # Decode the date into readable image\n",
        "    original_size_img_not_fixed = bytes(ONE_matched_google_full_resolution_images, 'ascii').decode('unicode-escape')\n",
        "    original_size_img = bytes(original_size_img_not_fixed, 'ascii').decode('unicode-escape')\n",
        "\n",
        "    print(original_size_img)\n",
        "\n",
        "    # ---------- All Image in Full Size ----------- #\n",
        "    # for index, fixed_full_res_image in enumerate(matched_google_full_resolution_images):\n",
        "    #     # https://stackoverflow.com/a/4004439/15164646 comment by Frédéric Hamidi\n",
        "    #     original_size_img_not_fixed = bytes(fixed_full_res_image, 'ascii').decode('unicode-escape')\n",
        "    #     original_size_img = bytes(original_size_img_not_fixed, 'ascii').decode('unicode-escape')\n",
        "    #     print(original_size_img)\n",
        "\n",
        "\n",
        "get_google_image_one_fullsize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eCzcnDdbH9E",
        "outputId": "2b677787-28a2-4af7-c3f9-73a79ace88d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full Resolution Images:\n",
            "https://m.media-amazon.com/images/M/MV5BNzQzOTk3OTAtNDQ0Zi00ZTVkLWI0MTEtMDllZjNkYzNjNTc4L2ltYWdlXkEyXkFqcGdeQXVyNjU0OTQ0OTY@._V1_.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Scrape Suggested search results: name, link, chips, thumbnail.**"
      ],
      "metadata": {
        "id": "2Cz9LlebZLlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, lxml, re, datetime\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\":\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"q\": \"leica m6\",\n",
        "    \"tbm\": \"isch\",\n",
        "    \"ijn\": \"0\",\n",
        "}\n",
        "\n",
        "html = requests.get(\"https://www.google.com/search\", params=params, headers=headers)\n",
        "soup = BeautifulSoup(html.text, 'lxml')"
      ],
      "metadata": {
        "id": "fObndNx2PJDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suggested_search_data():\n",
        "    for suggested_search in soup.select('.PKhmud.sc-it.tzVsfd'):\n",
        "        suggested_search_name = suggested_search.select_one('.hIOe2').text\n",
        "        suggested_search_link = f\"https://www.google.com{suggested_search.a['href']}\"\n",
        "\n",
        "        # https://regex101.com/r/y51ZoC/1\n",
        "        suggested_search_chips = ''.join(re.findall(r'=isch&chips=(.*?)&hl=en-US', suggested_search_link))\n",
        "        print(f\"{suggested_search_name}\\n{suggested_search_link}\\n{suggested_search_chips}\\n\")\n",
        "\n",
        "    # this steps could be refactored to a more compact\n",
        "    all_script_tags = soup.select('script')\n",
        "\n",
        "    # https://regex101.com/r/48UZhY/6\n",
        "    matched_images_data = ''.join(re.findall(r\"AF_initDataCallback\\(({key: 'ds:1'.*?)\\);</script>\", str(all_script_tags)))\n",
        "\n",
        "    # https://kodlogs.com/34776/json-decoder-jsondecodeerror-expecting-property-name-enclosed-in-double-quotes\n",
        "    # if you try to json.loads() without json.dumps() it will throw an error:\n",
        "    # \"Expecting property name enclosed in double quotes\"\n",
        "    matched_images_data_fix = json.dumps(matched_images_data)\n",
        "    matched_images_data_json = json.loads(matched_images_data_fix)\n",
        "\n",
        "    # search for only suggested search thumbnails related\n",
        "    # https://regex101.com/r/ITluak/2\n",
        "    suggested_search_thumbnails_data = ','.join(re.findall(r'{key(.*?)\\[null,\\\"Size\\\"', matched_images_data_json))\n",
        "\n",
        "    # https://regex101.com/r/MyNLUk/1\n",
        "    suggested_search_thumbnail_links_not_fixed = re.findall(r'\\\"(https:\\/\\/encrypted.*?)\\\"', suggested_search_thumbnails_data)\n",
        "\n",
        "    print('Suggested Search Thumbnails:')  # in order\n",
        "    for suggested_search_fixed_thumbnail in suggested_search_thumbnail_links_not_fixed:\n",
        "        # https://stackoverflow.com/a/4004439/15164646 comment by Frédéric Hamidi\n",
        "        suggested_search_thumbnail = bytes(suggested_search_fixed_thumbnail, 'ascii').decode('unicode-escape')\n",
        "        print(suggested_search_thumbnail)\n",
        "\n",
        "\n",
        "get_suggested_search_data()"
      ],
      "metadata": {
        "id": "ZQA-pvL9POUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Scrape Google images: title, link, source, thumbnail, original resolution image (and download them):**"
      ],
      "metadata": {
        "id": "6ZmviPvOYkef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, lxml, re, datetime\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\":\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582\"\n",
        "}\n",
        "\n",
        "params = {\n",
        "    \"q\": \"leica M6\",\n",
        "    \"tbm\": \"isch\",\n",
        "    \"ijn\": \"0\",\n",
        "}\n",
        "\n",
        "html = requests.get(\"https://www.google.com/search\", params=params, headers=headers)\n",
        "soup = BeautifulSoup(html.text, 'lxml')\n",
        "\n",
        "def get_google_images_data():\n",
        "\n",
        "    print('\\nGoogle Images Metadata:')\n",
        "    # for google_image in soup.select('.isv-r.PNCib.MSM1fd.BUooTd'):\n",
        "\n",
        "    #     title = google_image.select_one('.VFACy.kGQAp.sMi44c.lNHeqe.WGvvNb')['title']\n",
        "    #     source = google_image.select_one('.fxgdke').text\n",
        "    #     link = google_image.select_one('.VFACy.kGQAp.sMi44c.lNHeqe.WGvvNb')['href']\n",
        "    #     print(f'{title}\\n{source}\\n{link}\\n')\n",
        "\n",
        "    # this steps could be refactored to a more compact\n",
        "    all_script_tags = soup.select('script')\n",
        "\n",
        "    # # https://regex101.com/r/48UZhY/4\n",
        "    matched_images_data = ''.join(re.findall(r\"AF_initDataCallback\\(([^<]+)\\);\", str(all_script_tags)))\n",
        "\n",
        "    # https://kodlogs.com/34776/json-decoder-jsondecodeerror-expecting-property-name-enclosed-in-double-quotes\n",
        "    # if you try to json.loads() without json.dumps() it will throw an error:\n",
        "    # \"Expecting property name enclosed in double quotes\"\n",
        "    matched_images_data_fix = json.dumps(matched_images_data)\n",
        "    matched_images_data_json = json.loads(matched_images_data_fix)\n",
        "\n",
        "    # https://regex101.com/r/pdZOnW/3\n",
        "    matched_google_image_data = re.findall(r'\\[\\\"GRID_STATE0\\\",null,\\[\\[1,\\[0,\\\".*?\\\",(.*),\\\"All\\\",', matched_images_data_json)\n",
        "\n",
        "    # https://regex101.com/r/NnRg27/1\n",
        "    matched_google_images_thumbnails = ', '.join(\n",
        "        re.findall(r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]',\n",
        "                   str(matched_google_image_data))).split(', ')\n",
        "\n",
        "    print('Google Image Thumbnails:')  # in order\n",
        "    for fixed_google_image_thumbnail in matched_google_images_thumbnails:\n",
        "        # https://stackoverflow.com/a/4004439/15164646 comment by Frédéric Hamidi\n",
        "        google_image_thumbnail_not_fixed = bytes(fixed_google_image_thumbnail, 'ascii').decode('unicode-escape')\n",
        "\n",
        "        # after first decoding, Unicode characters are still present. After the second iteration, they were decoded.\n",
        "        google_image_thumbnail = bytes(google_image_thumbnail_not_fixed, 'ascii').decode('unicode-escape')\n",
        "        print(google_image_thumbnail)\n",
        "\n",
        "    # removing previously matched thumbnails for easier full resolution image matches.\n",
        "    removed_matched_google_images_thumbnails = re.sub(\n",
        "        r'\\[\\\"(https\\:\\/\\/encrypted-tbn0\\.gstatic\\.com\\/images\\?.*?)\\\",\\d+,\\d+\\]', '', str(matched_google_image_data))\n",
        "\n",
        "    # https://regex101.com/r/fXjfb1/4\n",
        "    # https://stackoverflow.com/a/19821774/15164646\n",
        "    matched_google_full_resolution_images = re.findall(r\"(?:'|,),\\[\\\"(https:|http.*?)\\\",\\d+,\\d+\\]\",\n",
        "                                                       removed_matched_google_images_thumbnails)\n",
        "\n",
        "    print('\\nFull Resolution Images:')  # in order\n",
        "    for index, fixed_full_res_image in enumerate(matched_google_full_resolution_images):\n",
        "        # https://stackoverflow.com/a/4004439/15164646 comment by Frédéric Hamidi\n",
        "        original_size_img_not_fixed = bytes(fixed_full_res_image, 'ascii').decode('unicode-escape')\n",
        "        original_size_img = bytes(original_size_img_not_fixed, 'ascii').decode('unicode-escape')\n",
        "        print(original_size_img)\n",
        "\n",
        "        # ------------------------------------------------\n",
        "        # Download original images\n",
        "\n",
        "        # print(f'Downloading {index} image...')\n",
        "\n",
        "        opener=urllib.request.build_opener()\n",
        "        opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582')]\n",
        "        urllib.request.install_opener(opener)\n",
        "\n",
        "        # urllib.request.urlretrieve(original_size_img, f'YOUR_LOCALFOLDER/YOUR_FILE_NAME.jpg')\n",
        "\n",
        "\n",
        "get_google_images_data()"
      ],
      "metadata": {
        "id": "E9p5kabAYi8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google-Images-Search**\n",
        "[User Glide](https://pypi.org/project/Google-Images-Search/)"
      ],
      "metadata": {
        "id": "J8thaJqpPc8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Google-Images-Search"
      ],
      "metadata": {
        "id": "bwlrogvFmRMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'AIzaSyBhSvIw0r_FidHoaj56xByvXERuGkZGOXo'\n",
        "search_engine_cx = '120337b42d147448d'"
      ],
      "metadata": {
        "id": "NLE2FDGBAT9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_search import GoogleImagesSearch\n",
        "\n",
        "# https://pypi.org/project/Google-Images-Search/\n",
        "# you can provide API key and CX using arguments,\n",
        "# or you can set environment variables: GCS_DEVELOPER_KEY, GCS_CX\n",
        "gis = GoogleImagesSearch(api_key, search_engine_cx)\n",
        "\n",
        "# define search params:\n",
        "_search_params = {\n",
        "    'q': 'apple',\n",
        "    'num': 1\n",
        "}\n",
        "\n",
        "# this will only search for images:\n",
        "gis.search(search_params=_search_params)\n"
      ],
      "metadata": {
        "id": "zj6wLMgKARGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_search import GoogleImagesSearch\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "# in this case we're using PIL to keep the BytesIO as an image object\n",
        "# that way we don't have to wait for disk save / write times\n",
        "# the image is simply kept in memory\n",
        "# this example should display 3 pictures of puppies!\n",
        "\n",
        "gis = GoogleImagesSearch(api_key, search_engine_cx)\n",
        "\n",
        "my_bytes_io = BytesIO()\n",
        "\n",
        "gis.search({'q': 'korea maru', 'num': 1})\n",
        "\n",
        "\n",
        "for image in gis.results():\n",
        "    # here we tell the BytesIO object to go back to address 0\n",
        "    my_bytes_io.seek(0)\n",
        "\n",
        "    # take raw image data\n",
        "    raw_image_data = image.get_raw_data()\n",
        "\n",
        "    # this function writes the raw image data to the object\n",
        "    image.copy_to(my_bytes_io, raw_image_data)\n",
        "\n",
        "    # or without the raw data which will be automatically taken\n",
        "    # inside the copy_to() method\n",
        "    image.copy_to(my_bytes_io)\n",
        "\n",
        "    # we go back to address 0 again so PIL can read it from start to finish\n",
        "    my_bytes_io.seek(0)\n",
        "\n",
        "    # create a temporary image object\n",
        "    temp_img = Image.open(my_bytes_io)\n",
        "    \n",
        "    # show it in the default system photo viewer\n",
        "    # temp_img.show()\n",
        "    display(temp_img)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "6b9UEjlHGREy",
        "outputId": "eb485f17-6f86-47bb-adf4-e2ca17ada177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a628a190c977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# create a temporary image object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtemp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_bytes_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# show it in the default system photo viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3008\u001b[0m     raise UnidentifiedImageError(\n\u001b[0;32m-> 3009\u001b[0;31m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3010\u001b[0m     )\n\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f3c704e54d0>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SerpApi - Google Image Search**\n",
        "[SerpApi](https://serpapi.com/images-results)"
      ],
      "metadata": {
        "id": "rX9xS8EuiVKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMiy2zYFijJC",
        "outputId": "7ed94565-fe50-4938-be9f-136035bc2f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.1.tar.gz (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from google-search-results) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (1.25.11)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->google-search-results) (2021.10.8)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.1-py3-none-any.whl size=25789 sha256=7a7783314fb418bf119a0d7c1e5627b1d0174cf4bd32471086b38941cd4f2cb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/a3/c5/364155118f298722dff2f79ae4dd7c91e92b433ad36d6f7e0e\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SerpAPI_key = 'aa1b5026e76afd67fd3d048579b3f84dbb9fd6a52b5f92741deb032cdce15c3f'"
      ],
      "metadata": {
        "id": "1MvwpX6liNgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, urllib.request, json # json for pretty output\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "\n",
        "def get_google_images():\n",
        "    params = {\n",
        "      \"api_key\": os.getenv(SerpAPI_key),\n",
        "      \"engine\": \"google\",\n",
        "      \"q\": \"pexels cat\",\n",
        "      \"tbm\": \"isch\"\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "\n",
        "    # print(json.dumps(results['suggested_searches'], indent=2, ensure_ascii=False))\n",
        "    # print(json.dumps(results['images_results'], indent=2, ensure_ascii=False))\n",
        "\n",
        "    # -----------------------\n",
        "    # Downloading images\n",
        "\n",
        "    for index, image in enumerate(results['images_results']):\n",
        "\n",
        "        print(f'Downloading {index} image...')\n",
        "        \n",
        "        opener=urllib.request.build_opener()\n",
        "        opener.addheaders=[('User-Agent','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.19582')]\n",
        "        urllib.request.install_opener(opener)\n",
        "\n",
        "        urllib.request.urlretrieve(image['original'], f'SerpApi_Images/original_size_img_{index}.jpg')\n",
        "\n",
        "get_google_images()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "ITqOhtnoif7Y",
        "outputId": "57c4b8d3-033c-4557-f03c-06cdc542ad4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://serpapi.com/search\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-804fa05b8f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'SerpApi_Images/original_size_img_{index}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mget_google_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-804fa05b8f94>\u001b[0m in \u001b[0;36mget_google_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Downloading images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images_results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Downloading {index} image...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'images_results'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "search = GoogleSearch({\n",
        "    \"q\": \"coffee\", \n",
        "    \"api_key\": SerpAPI_key\n",
        "  })\n",
        "result = search.get_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJp1sKro3YVa",
        "outputId": "c826dce0-5111-40f8-ed61-bbdb4911977e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://serpapi.com/search\n"
          ]
        }
      ]
    }
  ]
}